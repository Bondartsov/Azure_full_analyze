# core/analyze/repository_analysis.py

import os
from core.reports.generate import generate_report
from core.utils.cache import load_repo_data_from_cache, save_repo_data_to_cache
from core.utils.token_counter import count_tokens_in_repo
from core.logging.logger import log
from core.ai.report_generator import (
    generate_ai_report,
    generate_deep_report_for_repo,
    get_deep_reports_for_repo
)


def analyze_repository(project_name, repository, repo_changed, analysis_mode="fast"):
    """
    –ê–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è.
      - –ï—Å–ª–∏ analysis_mode == "fast", –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –±—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑.
      - –ï—Å–ª–∏ analysis_mode == "deep", —Å–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑, –∞ –∑–∞—Ç–µ–º –≥–ª—É–±–æ–∫–∏–π.
    """
    repository_name = repository.name

    print(f"DEBUG: –ê–Ω–∞–ª–∏–∑ {repository_name}, —Ä–µ–∂–∏–º: {analysis_mode}")
    log(f"üîç –ê–Ω–∞–ª–∏–∑ {repository_name}, —Ä–µ–∂–∏–º: {analysis_mode}")

    fast_results = analyze_repository_fast(project_name, repository_name, repo_changed)
    
    if not fast_results:
        return None

    if analysis_mode == "deep":
        print(f"DEBUG: –í–´–ó–´–í–ê–ï–ú –ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó –î–õ–Ø {repository_name}")
        log(f"üß† –ó–∞–ø—É—Å–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –ò–ò-–∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {repository_name}")
        print("DEBUG: –í—ã–∑–æ–≤ get_deep_reports_for_repo")
        deep_reports = analyze_repository_deep(project_name, repository_name, fast_results)

        fast_results["ai_reports"] = deep_reports

    return fast_results

def analyze_repository_fast(project_name, repository_name, repo_changed):
    """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤, –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤, –æ—Ç—á—ë—Ç."""
    if not repo_changed:
        cached_data = load_repo_data_from_cache(project_name, repository_name)
        if cached_data:
            total_tokens = cached_data.get("total_tokens", 0)
            files_data = cached_data.get("files", [])
            report_path = generate_report(project_name, repository_name, files_data)
            if report_path:
                log(f"üìÑ –û—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞ {repository_name} —Å–æ—Ö—Ä–∞–Ω—ë–Ω (–∏–∑ –∫—ç—à–∞): {report_path}")
                return {
                    "repository": repository_name,
                    "tokens": total_tokens,
                    "cached": True,
                    "files": files_data,
                    "report_path": report_path
                }
            else:
                log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á—ë—Ç–∞ –∏–∑ –∫—ç—à–∞ –¥–ª—è {repository_name}!", level="ERROR")
                return None
    files_data, total_tokens = count_tokens_in_repo(project_name, repository_name)
    report_path = generate_report(project_name, repository_name, files_data)
    save_repo_data_to_cache(project_name, repository_name, total_tokens, files_data)
    log(f"üìÑ –û—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞ {repository_name} —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_path}")
    
    return {
        "repository": repository_name,
        "tokens": total_tokens,
        "cached": False,
        "files": files_data,
        "report_path": report_path
    }
def analyze_repository_deep(project_name, repository_name, fast_results):
    """–ì–ª—É–±–æ–∫–∏–π –ò–ò-–∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–∂–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
    
    print(f"DEBUG: –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –¥–ª—è {repository_name}")
    log(f"üß† –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≥–ª—É–±–æ–∫–∏–π –ò–ò-–∞–Ω–∞–ª–∏–∑ –¥–ª—è {repository_name}")
    
    if not isinstance(fast_results, dict):
        raise ValueError("fast_results –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º, –∞ –Ω–µ —Å–ø–∏—Å–∫–æ–º")
    
    files_data = fast_results.get("files", [])
    print(f"DEBUG: –§–∞–π–ª—ã –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {len(files_data)} —à—Ç.")
    log(f"üîé –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {len(files_data)}")
    deep_reports = get_deep_reports_for_repo(project_name, repository_name, files_data)
    print(f"DEBUG: –ù–∞–π–¥–µ–Ω–æ {len(deep_reports)} –ò–ò-–æ—Ç—á—ë—Ç–æ–≤")
    log(f"üìù –ù–∞–π–¥–µ–Ω–æ {len(deep_reports)} –ò–ò-–æ—Ç—á—ë—Ç–æ–≤ –¥–ª—è {repository_name}")
    return deep_reports
def generate_deep_report_for_repo(project_name, repository_name, files_data):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ò–ò-–æ—Ç—á—ë—Ç –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è.
    """
    deep_report_paths = []
    
    for file_info in files_data:
        file_name = file_info.get("file_name")
        folder = file_info.get("folder", "root")
        file_content = file_info.get("content")
        if not file_content:
            continue
        try:
            report_path = generate_ai_report(project_name, repository_name, folder, file_name, file_content)
            deep_report_paths.append(report_path)
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ò–ò-–æ—Ç—á—ë—Ç–∞ –¥–ª—è —Ñ–∞–π–ª–∞ {file_name}: {e}", level="ERROR")
    
    aggregated_dir = os.path.join("ai_reports", project_name, repository_name)
    os.makedirs(aggregated_dir, exist_ok=True)
    aggregated_report_path = os.path.join(aggregated_dir, "aggregated_deep_report.txt")
    
    try:
        with open(aggregated_report_path, "w", encoding="utf-8") as f:
            header = f"–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ò–ò-–∞–Ω–∞–ª–∏–∑ –¥–ª—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è {repository_name}\n\n"
            f.write(header)
            for path in deep_report_paths:
                f.write(f"{path}\n")
        log(f"‚úÖ –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ò–ò-–æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {aggregated_report_path}")
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ò–ò-–æ—Ç—á—ë—Ç–∞: {e}", level="ERROR")

    return aggregated_report_path

def get_deep_reports_for_repo(project_name, repository_name, files_data):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö –ø—É—Ç–µ–π –∫ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º –ò–ò-–æ—Ç—á—ë—Ç–∞–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞.
    """
    log(f"üìÇ –ù–∞—á–∏–Ω–∞–µ–º –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ –≤ {repository_name}")
    deep_reports = []
    
    for file_info in files_data:
        file_name = file_info.get("file_name") or file_info.get("path")
        folder = file_info.get("folder", "root")
        file_content = file_info.get("content")
        print(f"DEBUG: –§–∞–π–ª—ã –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {len(files_data)} —à—Ç.")
        log(f"üß† –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {len(files_data)}")
        if not file_content:
            log(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª: {file_name}")
            continue
        try:
            log(f"üöÄ –í—ã–∑–æ–≤ generate_ai_report –¥–ª—è {file_name} –≤ –ø–∞–ø–∫–µ {folder}")
            report_path = generate_ai_report(project_name, repository_name, folder, file_name, file_content)
            
            if report_path:
                deep_reports.append(os.path.abspath(report_path))
                log(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω: {report_path}")
       
                print(f"DEBUG: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª {file_name} –≤ {folder}")
                log(f"üìù –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {file_name} –∏–∑ {folder}")
            
            else:
                log(f"‚ùå –û—Ç—á—ë—Ç –¥–ª—è {file_name} –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω!", level="ERROR")
            
            print(f"DEBUG: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª {file_name} –≤ {folder}")
            log(f"üìù –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {file_name} –∏–∑ {folder}")
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ò–ò-–æ—Ç—á—ë—Ç–∞ –¥–ª—è {file_name}: {e}", level="ERROR")
    log(f"üîç –ó–∞–≤–µ—Ä—à—ë–Ω –∞–Ω–∞–ª–∏–∑ {repository_name}, –Ω–∞–π–¥–µ–Ω–æ {len(deep_reports)} –æ—Ç—á—ë—Ç–æ–≤.")
    print(f"DEBUG: –°–æ–∑–¥–∞–Ω–Ω—ã–µ –ò–ò-–æ—Ç—á—ë—Ç—ã: {deep_reports}")
    return deep_reports