# core/utils/token_counter.py
# –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã

import os
from tqdm import tqdm
from core.azure.repos import get_repo_files
from dotenv import load_dotenv  # –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ .env
import tiktoken
from core.logging.logger import log  # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ª–æ–≥–≥–µ—Ä –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω
from core.utils.database import add_file_record  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ database.py
from core.azure.connection import connect_to_azure  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Azure
import hashlib  # –î–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ö–µ—à–∞

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env
load_dotenv()

# –ü–æ–ª—É—á–µ–Ω–∏–µ –±–µ–ª–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
WHITE_EXTENSIONS = set(ext.strip().lower() for ext in os.getenv("WHITE_EXTENSIONS", "").split(",") if ext.strip())
if not WHITE_EXTENSIONS:
    log("‚ö† –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è WHITE_EXTENSIONS –ø—É—Å—Ç–∞! –ë—É–¥—É—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤—Å–µ —Ñ–∞–π–ª—ã.", level="WARNING")
    print("‚ö† –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è WHITE_EXTENSIONS –ø—É—Å—Ç–∞! –ë—É–¥—É—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤—Å–µ —Ñ–∞–π–ª—ã.")
else:
    log(f"üìÇ –ë–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π: {WHITE_EXTENSIONS}")
    print(f"üìÇ –ë–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π: {WHITE_EXTENSIONS}")

def get_file_content(project_name, repository_name, file_path):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –ø–æ –µ–≥–æ –ø—É—Ç–∏ —á–µ—Ä–µ–∑ API Azure DevOps.
    """
    try:
        connection = connect_to_azure()
        git_client = connection.clients.get_git_client()

        log(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ {file_path} –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è {repository_name}...")
        content_generator = git_client.get_item_content(repository_name, path=file_path, project=project_name)

        # –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
        file_content = b"".join(content_generator).decode("utf-8", errors="ignore")

        if file_content:
            log(f"‚úÖ –§–∞–π–ª {file_path} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω ({len(file_content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            print(f"‚úÖ –§–∞–π–ª {file_path} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω ({len(file_content)} —Å–∏–º–≤–æ–ª–æ–≤)")
        else:
            log(f"‚ö† –§–∞–π–ª {file_path} –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å", level="WARNING")
            print(f"‚ö† –§–∞–π–ª {file_path} –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å")

        return file_content if file_content else ""
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}", level="ERROR")
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return ""

def count_tokens_in_repo(project_name, repository_name):
    """
    –°—á–∏—Ç–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã, —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ —Ñ–∞–π–ª–∞—Ö (—É –∫–æ—Ç–æ—Ä—ã—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –≤ WHITE_EXTENSIONS).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (files_data, total_tokens).
    files_data -> [{"path": ..., "tokens": int, "lines": int, "comments": int}, ...]
    """
    total_tokens = 0
    files_data = []
    log(f"üìä –ù–∞—á–∞–ª–æ –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤, —Å—Ç—Ä–æ–∫ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤ {repository_name} (–±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫).")

    files = get_repo_files(project_name, repository_name)
    if not files:
        log(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª—ã –¥–ª—è {repository_name}", level="WARNING")
        return [], 0

    for file_path in tqdm(files, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤"):
        _, ext = os.path.splitext(file_path.lower())
        if ext not in WHITE_EXTENSIONS:
            log(f"üîç –§–∞–π–ª {file_path} –ø—Ä–æ–ø—É—â–µ–Ω: —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ {ext} –Ω–µ –≤ –±–µ–ª–æ–º —Å–ø–∏—Å–∫–µ.")
            continue

        content = get_file_content(project_name, repository_name, file_path)

        if not content.strip():
            log(f"üîç –§–∞–π–ª {file_path} –ø—Ä–æ–ø—É—â–µ–Ω: –ø—É—Å—Ç–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ.")
            continue

        log(f"üìù –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ {file_path}: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"üìù –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ {file_path}: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
        tokens_count = count_tokens_in_text(content)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ (–ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–±)
        lines_count = content.count('\n') + 1

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (–Ω–∞–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)
        comments_count = count_comments_naive(content, ext)

        # –í—ã—á–∏—Å–ª—è–µ–º —Ö–µ—à-—Å—É–º–º—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
        hash_value = hashlib.sha256(content.encode('utf-8')).hexdigest()

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        success = add_file_record(
            project_name=project_name,
            repository_name=repository_name,
            folder_name=os.path.dirname(file_path),
            file_name=os.path.basename(file_path),
            file_path=file_path,
            content=content,
            lines=lines_count,
            comments=comments_count,
            tokens=tokens_count,
            hash_value=hash_value,
            processed=False  # –§–ª–∞–≥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ False
        )

        if success:
            log(f"‚úÖ –§–∞–π–ª {file_path} —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω/–æ–±–Ω–æ–≤–ª—ë–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.")
        else:
            log(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å —Ñ–∞–π–ª {file_path} –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.", level="ERROR")

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ files_data –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        files_data.append({
            "path": file_path,
            "tokens": tokens_count,
            "lines": lines_count,
            "comments": comments_count,
        })
        total_tokens += tokens_count

    log(f"üìà –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ {repository_name}: {total_tokens}")
    return files_data, total_tokens

def read_file_content(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
            log(f"üìÇ –§–∞–π–ª {file_path} —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω, {len(content)} —Å–∏–º–≤–æ–ª–æ–≤.")
            return content
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}", level="ERROR")
        return ""

def count_tokens_in_text(text, model="cl100k_base"):
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º tiktoken.
    –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —è–≤–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É 'cl100k_base'.
    """
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —è–≤–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É 'cl100k_base'
        encoding = tiktoken.get_encoding("cl100k_base")
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ 'cl100k_base': {e}", level="ERROR")
        raise e

    tokens = encoding.encode(text)
    token_count = len(tokens)
    log(f"ü™Ñ –ü–æ–¥—Å—á–∏—Ç–∞–Ω–æ {token_count} —Ç–æ–∫–µ–Ω–æ–≤.")
    print(f"ü™Ñ –ü–æ–¥—Å—á–∏—Ç–∞–Ω–æ {token_count} —Ç–æ–∫–µ–Ω–æ–≤.")
    return token_count

def split_text(text, max_tokens=3000):
    """
    –†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏, –∫–∞–∂–¥–∞—è –∏–∑ –∫–æ—Ç–æ—Ä–æ–π –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç max_tokens.
    –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —è–≤–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É 'cl100k_base'.
    """
    try:
        encoding = tiktoken.get_encoding("cl100k_base")
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ 'cl100k_base': {e}", level="ERROR")
        raise e

    tokens = encoding.encode(text)
    parts = []
    current_tokens = []

    for token in tokens:
        current_tokens.append(token)
        if len(current_tokens) >= max_tokens:
            decoded_part = encoding.decode(current_tokens)
            parts.append(decoded_part)
            log(f"üìö –†–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ {len(decoded_part)} —Å–∏–º–≤–æ–ª–æ–≤.")
            print(f"üìö –†–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ {len(decoded_part)} —Å–∏–º–≤–æ–ª–æ–≤.")
            current_tokens = []

    if current_tokens:
        decoded_part = encoding.decode(current_tokens)
        parts.append(decoded_part)
        log(f"üìö –†–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ {len(decoded_part)} —Å–∏–º–≤–æ–ª–æ–≤.")
        print(f"üìö –†–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ {len(decoded_part)} —Å–∏–º–≤–æ–ª–æ–≤.")

    log(f"üìë –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π –ø–æ—Å–ª–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è: {len(parts)}")
    print(f"üìë –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π –ø–æ—Å–ª–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è: {len(parts)}")
    return parts

def count_comments_naive(content, ext):
    """
    –ù–∞–∏–≤–Ω–æ —Å—á–∏—Ç–∞–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –¥–ª—è —Ä—è–¥–∞ —è–∑—ã–∫–æ–≤:
    - C-like (C#, C++, Java, JS): –∏—â–µ–º —Å—Ç—Ä–æ–∫–∏ //, /*...*/
    - Python: —Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å #
    –∏ —Ç.–¥.
    """
    lines = content.split('\n')
    comment_lines = 0
    in_block_comment = False

    for line in lines:
        stripped = line.strip()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Python-style #
        if ext == '.py':
            if stripped.startswith('#'):
                comment_lines += 1
                continue

        # C++/Java/C#/JS single line //
        if stripped.startswith('//') and ext in ['.cpp', '.c', '.cs', '.java', '.js', '.ts', '.jsx', '.tsx']:
            comment_lines += 1
            continue

        # –ù–∞—á–∞–ª–æ –±–ª–æ–∫–æ–≤–æ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è /* */
        if '/*' in stripped and ext in ['.cpp', '.c', '.cs', '.java', '.js', '.ts', '.jsx', '.tsx']:
            in_block_comment = True
            comment_lines += 1
            # –ï—Å–ª–∏ –±–ª–æ–∫–æ–≤—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∑–∞–∫—Ä—ã–≤–∞–µ—Ç—Å—è –≤ —Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ
            if '*/' in stripped and stripped.index('/*') < stripped.index('*/'):
                in_block_comment = False
            continue

        # –í–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–æ–≤–æ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
        if in_block_comment:
            comment_lines += 1
            if '*/' in stripped:
                in_block_comment = False
            continue

    log(f"üìù –ù–∞–π–¥–µ–Ω–æ {comment_lines} —Å—Ç—Ä–æ–∫ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è {ext}.")
    print(f"üìù –ù–∞–π–¥–µ–Ω–æ {comment_lines} —Å—Ç—Ä–æ–∫ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è {ext}.")
    return comment_lines