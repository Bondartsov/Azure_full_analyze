import tiktoken
from tqdm import tqdm

from core.azure.repos import get_repo_files, get_file_content
from core.logging.logger import log

# –ò—Å–∫–ª—é—á–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
EXCLUDE_EXTENSIONS = {
    ".jpg", ".jpeg", ".png", ".gif", ".svg", ".bmp", ".tiff", ".ico",  # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    ".mp4", ".avi", ".mov", ".mkv", ".flv", ".wmv", ".webm",           # –í–∏–¥–µ–æ
    ".mp3", ".wav", ".ogg", ".flac", ".aac", ".wma",                   # –ê—É–¥–∏–æ
    ".ttf", ".otf", ".woff", ".woff2",                                 # –®—Ä–∏—Ñ—Ç—ã
    ".bin", ".dylib", ".so", ".o", ".dll",                             # –ë–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã
    ".zip", ".tar", ".gz", ".bz2", ".7z",                              # –ê—Ä—Ö–∏–≤—ã
    ".ckpt", ".pb", ".pt", ".onnx",                                    # –ú–æ–¥–µ–ª–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π
    ".sqlite", ".db", ".sql", ".mdb", ".accdb"                         # –§–∞–π–ª—ã –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
}

def count_tokens_in_repo(project_name, repository_name):
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏, –∏—Å–∫–ª—é—á–∞—è –±–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂: (list_of_dicts, total_tokens),
    –≥–¥–µ list_of_dicts = [
        {"path": "–ø—É—Ç—å/–∫/—Ñ–∞–π–ª—É.py", "tokens": 123},
        ...
    ]
    """
    total_tokens = 0
    files_data = []  # –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π. –ö–∞–∂–¥—ã–π —Å–ª–æ–≤–∞—Ä—å: {"path": <str>, "tokens": <int>}
    excluded_files = 0

    log(f"üìä –ù–∞—á–∞–ª–æ –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ {repository_name}...")

    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
    files = get_repo_files(project_name, repository_name)
    if not files:
        log(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª—ã –¥–ª—è {repository_name}.", level="WARNING")
        return [], 0

    for file_path in tqdm(files, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤"):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        if any(file_path.lower().endswith(ext) for ext in EXCLUDE_EXTENSIONS):
            log(f"‚ö† –§–∞–π–ª {file_path} –∏—Å–∫–ª—é—á—ë–Ω (–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç).")
            excluded_files += 1
            continue

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        content = get_file_content(project_name, repository_name, file_path)
        if not content.strip():
            log(f"‚ö† –§–∞–π–ª {file_path} –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ.")
            continue

        # –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤
        tokens = count_tokens_in_text(content)
        files_data.append({
            "path": file_path,
            "tokens": tokens
        })
        total_tokens += tokens

        log(f"üìÑ –§–∞–π–ª {file_path} ‚Üí {tokens} —Ç–æ–∫–µ–Ω–æ–≤")

    log(f"‚úÖ DEBUG: –í —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ **{repository_name}** –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ **{len(files_data)}** "
        f"—Ñ–∞–π–ª–æ–≤, –∏—Å–∫–ª—é—á–µ–Ω–æ **{excluded_files}**, –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤: **{total_tokens}**")

    return files_data, total_tokens

def count_tokens_in_text(text, model_encoding="cl100k_base"):
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É—è —É–∫–∞–∑–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∫–æ–¥–∏—Ä–æ–≤–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é cl100k_base).
    """
    encoding = tiktoken.get_encoding(model_encoding)
    return len(encoding.encode(text))
