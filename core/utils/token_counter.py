import tiktoken
from tqdm import tqdm
import os

from core.azure.repos import get_repo_files, get_file_content
from core.logging.logger import log

WHITE_EXTENSIONS = {
    # Back-end
    ".py", ".java", ".cs", ".c", ".h", ".cpp", ".hpp", ".go", ".php", ".rb", ".rs", ".kt", ".scala",
    # Node.js (server)
    ".js", ".mjs", ".cjs", ".ts",
    # Frontend (Web)
    ".html", ".css", ".scss", ".sass", ".jsx", ".tsx", ".vue", ".svelte",
    # iOS
    ".swift",  # Swift
    ".m",      # Objective-C
    ".mm",     # Objective-C++
    # Android (Java/Kotlin —É–∂–µ –≤—ã—à–µ)
    # –ö—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã–µ
    ".dart",   # Flutter
}

def count_tokens_in_repo(project_name, repository_name):
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¢–û–õ–¨–ö–û –≤ —Ñ–∞–π–ª–∞—Ö, —á—å–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –≤ WHITE_EXTENSIONS.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂: (files_data, total_tokens), –≥–¥–µ
        files_data = [
            {"path": <—Å—Ç—Ä–æ–∫–∞>, "tokens": <—á–∏—Å–ª–æ>},
            ...
        ]
        total_tokens (int)
    """
    total_tokens = 0
    files_data = []
    excluded_files = 0

    log(f"üìä –ù–∞—á–∞–ª–æ –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ {repository_name} (–±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫)...")

    files = get_repo_files(project_name, repository_name)
    if not files:
        log(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª—ã –¥–ª—è {repository_name}.", level="WARNING")
        return [], 0

    for file_path in tqdm(files, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤"):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        _, ext = os.path.splitext(file_path.lower())

        if ext not in WHITE_EXTENSIONS:
            excluded_files += 1
            continue

        content = get_file_content(project_name, repository_name, file_path)
        if not content.strip():
            log(f"‚ö† –§–∞–π–ª {file_path} –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ.")
            continue

        tokens_count = count_tokens_in_text(content)
        files_data.append({
            "path": file_path,
            "tokens": tokens_count
        })
        total_tokens += tokens_count

        log(f"üìÑ –§–∞–π–ª {file_path} ‚Üí {tokens_count} —Ç–æ–∫–µ–Ω–æ–≤")

    log(f"‚úÖ DEBUG: –í —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ {repository_name} "
        f"–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(files_data)} —Ñ–∞–π–ª–æ–≤ (–ø–æ –±–µ–ª–æ–º—É —Å–ø–∏—Å–∫—É), "
        f"–ø—Ä–æ–ø—É—â–µ–Ω–æ {excluded_files}, –≤—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens}")

    return files_data, total_tokens

def count_tokens_in_text(text, model_encoding="cl100k_base"):
    """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É—è —É–∫–∞–∑–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∫–æ–¥–∏—Ä–æ–≤–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é cl100k_base)."""
    encoding = tiktoken.get_encoding(model_encoding)
    return len(encoding.encode(text))
