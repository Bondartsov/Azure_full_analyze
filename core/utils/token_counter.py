import tiktoken
from tqdm import tqdm

from core.azure.repos import get_repo_files, get_file_content
from core.logging.logger import log

# –ò—Å–∫–ª—é—á–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
EXCLUDE_EXTENSIONS = {
    ".jpg", ".jpeg", ".png", ".gif", ".svg", ".bmp", ".tiff", ".ico",  # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    ".mp4", ".avi", ".mov", ".mkv", ".flv", ".wmv", ".webm",           # –í–∏–¥–µ–æ
    ".mp3", ".wav", ".ogg", ".flac", ".aac", ".wma",                   # –ê—É–¥–∏–æ
    ".ttf", ".otf", ".woff", ".woff2",                                 # –®—Ä–∏—Ñ—Ç—ã
    ".bin", ".dylib", ".so", ".o", ".dll",                             # –ë–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã
    ".zip", ".tar", ".gz", ".bz2", ".7z",                              # –ê—Ä—Ö–∏–≤—ã
    ".ckpt", ".pb", ".pt", ".onnx",                                    # –ú–æ–¥–µ–ª–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π
    ".sqlite", ".db", ".sql", ".mdb", ".accdb"                         # –§–∞–π–ª—ã –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
}

def count_tokens_in_repo(project_name, repository_name):
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏, –∏—Å–∫–ª—é—á–∞—è –±–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–∞–π–ª—ã.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂: (files_data, total_tokens), –≥–¥–µ
        files_data = [
            {"path": "–ø—É—Ç—å/–∫/—Ñ–∞–π–ª—É", "tokens": int},
            ...
        ]
    """
    total_tokens = 0
    files_data = []
    excluded_files = 0

    log(f"üìä –ù–∞—á–∞–ª–æ –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ {repository_name}...")

    files = get_repo_files(project_name, repository_name)
    if not files:
        log(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª—ã –¥–ª—è {repository_name}.", level="WARNING")
        return [], 0

    for file_path in tqdm(files, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤"):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã —Å –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–º–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏
        if any(file_path.lower().endswith(ext) for ext in EXCLUDE_EXTENSIONS):
            log(f"‚ö† –§–∞–π–ª {file_path} –∏—Å–∫–ª—é—á—ë–Ω (–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç).")
            excluded_files += 1
            continue

        content = get_file_content(project_name, repository_name, file_path)
        if not content.strip():
            log(f"‚ö† –§–∞–π–ª {file_path} –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ.")
            continue

        tokens = count_tokens_in_text(content)
        files_data.append({
            "path": file_path,
            "tokens": tokens
        })
        total_tokens += tokens

        log(f"üìÑ –§–∞–π–ª {file_path} ‚Üí {tokens} —Ç–æ–∫–µ–Ω–æ–≤")

    log(f"‚úÖ DEBUG: –í —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ {repository_name} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(files_data)} —Ñ–∞–π–ª–æ–≤, "
        f"–∏—Å–∫–ª—é—á–µ–Ω–æ {excluded_files}, –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens}")

    return files_data, total_tokens


def count_tokens_in_text(text, model_encoding="cl100k_base"):
    """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É—è 'cl100k_base')."""
    encoding = tiktoken.get_encoding(model_encoding)
    return len(encoding.encode(text))
